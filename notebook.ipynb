from train import train_vae
from vae import VAE_bayesian
import torch
import matplotlib.pyplot as plt

bayesian = True #Bayesian or non-bayesian setting
train_vae(epochs = 200, batch_size = 128, bayesian = bayesian)



#Load model settings and statistics:
if bayesian:
  model_dict = torch.load('trained.model.bayesian.pth')
else:
  model_dict = torch.load('trained.model.non_bayesian.pth')


from vae import VAE_bayesian
import torch
import matplotlib.pyplot as plt

bayesian = True


if bayesian:
  pp = 4
  model_dict = torch.load('trained.model.bayesian.pth')
else:
  pp = 3
  model_dict = torch.load('trained.model.non_bayesian.pth')

plt.figure(figsize=(18,4))
plt.subplot(1,pp,1)
plt.title("Reconstruction loss")
ax1 = plt.gca()
ax2 = ax1.twinx()
ax1.set_xlabel('EPOCH', c='C3')
ax1.tick_params(axis='x', labelcolor='C3')
ax1.set_ylabel('Reconstruction Loss (RL)', c='C0')
ax1.tick_params(axis='y', labelcolor='C0') 
ax1.plot(model_dict['stats']['rl'], lw=2, c='C0', label = 'RL')
ax1.legend()

plt.subplot(1,pp,2)
plt.title("KL latent")
ax1 = plt.gca()
ax1.set_xlabel('EPOCH', c='C3')
ax1.tick_params(axis='x', labelcolor='C3')
ax1.set_ylabel('Kullback-Leibler divergence loss (KL)', c='C2')
ax1.tick_params(axis='y', labelcolor='C2')
ax1.plot(model_dict['stats']['kl'], lw=2, c='C2', label = 'KL latent')
ax1.legend()
ax1.grid(False)

plt.subplot(1,pp,3)
plt.title(r"$|Spearman\ \rho|$ correlation to experimental data")
plt.xlabel('EPOCH', c='C3')
plt.tick_params(axis='x', labelcolor='C3')
plt.plot(model_dict['stats']['cor'], lw=2, c='C9', label="Our result")
plt.tick_params(axis='y', labelcolor='C9')
plt.ylim(0.5,0.8)
plt.axhline(y=0.74388, c='C6', lw=2, label=f'Paper result ' + rf'$|\rho|={round(0.74388, 4)}$')
plt.legend()

if bayesian:
  plt.subplot(1,pp,4)
  plt.title("KL parameters")
  ax1 = plt.gca()
  ax1.set_xlabel('EPOCH', c='C3')
  ax1.tick_params(axis='x', labelcolor='C3')
  ax1.set_ylabel('Kullback-Leibler divergence loss (KL)', c='C2')
  ax1.tick_params(axis='y', labelcolor='C2')
  ax1.plot(model_dict['stats']['KLB'], lw=2, c='C0', label = 'KLB')
  ax1.legend()
  ax1.grid(False)

plt.tight_layout()
plt.show()